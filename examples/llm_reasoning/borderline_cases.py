#!/usr/bin/env python3
"""
LLM Reasoner é‚Šç•Œæƒ…æ³ç¯„ä¾‹

æ¼”ç¤ºå¦‚ä½•åœ¨é‚Šç•Œæƒ…æ³ä¸‹è§¸ç™¼ LLM æ¨ç†ï¼Œä»¥åŠå¦‚ä½•è™•ç†æ¨ç†çµæœã€‚
"""

import requests
import json
from typing import Dict, Any

# é…ç½®
API_BASE = "http://localhost:8000/v2"
TIMEOUT = 5.0

def create_borderline_request() -> Dict[str, Any]:
    """å‰µå»ºæœƒè§¸ç™¼ LLM æ¨ç†çš„é‚Šç•Œæƒ…æ³è«‹æ±‚"""
    return {
        "symbol": "ETHUSDT",
        "version": "2.0",
        "side_hint": "short",
        "ts": "2025-09-15T14:30:00Z",
        "tf": "15m",
        "features": {
            # æ¨™æº–æŠ€è¡“æŒ‡æ¨™
            "sigma_1m": 0.0018,
            "skew_1m": -0.72,
            "Z_4H": -0.9,
            "Z_1H": -0.7,
            "Z_15m": -0.6,

            # ä¸€è‡´æ€§æŒ‡æ¨™ (ç•¥ä½ï¼Œé‚Šç•Œæƒ…æ³)
            "C_align": 0.82,
            "C_of": 0.78,
            "C_vision": 0.76,

            # v2: Likert-7 æ–¹å‘ç·¨ç¢¼
            "direction": {
                "dir_score_htf": -0.75,
                "dir_htf": -2,           # ä¸­åº¦çœ‹ç©º
                "dir_score_ltf": -0.65,
                "dir_ltf": -2,
                "dir_score_micro": -0.55,
                "dir_micro": -1          # è¼•åº¦çœ‹ç©º
            },

            # v2: FinGPT æ–°èåˆ†æ
            "news": {
                "sentiment_score": -0.3,
                "event_risk": 0.15,
                "headline_summary": "Fed signals potential rate hike, crypto markets cautious"
            },

            # è¡çªä¿¡è™Ÿ (æœƒè§¸ç™¼ LLM)
            "pine_match": True,
            "of_divergence": True,      # OrderFlow èƒŒé›¢
            "vision_conflict": True     # è¦–è¦ºæ¨¡å¼è¡çª
        },
        "pgm": {
            "p_hit": 0.74,              # é‚Šç•Œå€¼ï¼æœƒè§¸ç™¼ LLM
            "mae_q999": 0.0058,
            "slip_q95": 0.0004,
            "t_hit_q50_bars": 6,

            # v2: ä¿å½¢é æ¸¬ç½®ä¿¡å€é–“
            "conformal_ci": {
                "p_hit_lower": 0.71,
                "p_hit_upper": 0.77,
                "coverage_prob": 0.95
            }
        }
    }

def analyze_llm_response(decision: Dict[str, Any]) -> None:
    """åˆ†æ LLM æ¨ç†çµæœ"""
    print("=" * 60)
    print("ğŸ¤– LLM æ¨ç†åˆ†æ")
    print("=" * 60)

    if "llm_reasoning" not in decision:
        print("âŒ LLM æ¨ç†æœªè§¸ç™¼ (å¯èƒ½ä¸åœ¨é‚Šç•Œç¯„åœ)")
        return

    llm = decision["llm_reasoning"]

    print(f"âœ… LLM æ¨ç†å·²è§¸ç™¼")
    print(f"ğŸ“ Rationale: {llm['rationale']}")
    print(f"ğŸ·ï¸  Meta Tag: {llm['meta_tag']}")
    print(f"ğŸ“Š LLM ç½®ä¿¡åº¦: {llm['c_llm']:.2f}")
    print(f"â±ï¸  æ¨ç†è€—æ™‚: {llm.get('reasoning_time_ms', 'N/A')}ms")
    print(f"ğŸ¯ è§¸ç™¼åŸå› : {llm.get('triggered_by', 'borderline_p_hit')}")

    # åˆ†ææ¨ç†è³ªé‡
    confidence = llm['c_llm']
    if confidence > 0.8:
        print("ğŸŸ¢ é«˜è³ªé‡æ¨ç† - å¯ä»¥ä¿¡è³´")
    elif confidence > 0.6:
        print("ğŸŸ¡ ä¸­ç­‰è³ªé‡æ¨ç† - éœ€è¦è¬¹æ…")
    else:
        print("ğŸ”´ ä½è³ªé‡æ¨ç† - å»ºè­°å›é€€åˆ°ç´”æ•¸å€¼æ±ºç­–")

def demonstrate_llm_reasoning():
    """æ¼”ç¤º LLM æ¨ç†åŠŸèƒ½"""
    print("ğŸš€ P1-System v2 LLM Reasoner æ¼”ç¤º")
    print("=" * 60)

    # å‰µå»ºé‚Šç•Œæƒ…æ³è«‹æ±‚
    request = create_borderline_request()

    print("ğŸ“¤ ç™¼é€é‚Šç•Œæƒ…æ³è«‹æ±‚...")
    print(f"   p_hit: {request['pgm']['p_hit']} (é‚Šç•Œå€¼)")
    print(f"   è¡çªä¿¡è™Ÿ: {request['features']['of_divergence']}")

    try:
        # èª¿ç”¨ v2 API
        response = requests.post(
            f"{API_BASE}/decide/enter",
            json=request,
            timeout=TIMEOUT
        )
        response.raise_for_status()
        decision = response.json()

        # åŸºæœ¬æ±ºç­–çµæœ
        print(f"\nğŸ“‹ æ±ºç­–çµæœ:")
        print(f"   å…è¨±äº¤æ˜“: {'âœ…' if decision['allow'] else 'âŒ'}")
        print(f"   å»ºè­°æ–¹å‘: {decision.get('side', 'N/A')}")
        print(f"   åˆ†é…æ¯”ä¾‹: {decision.get('alloc_equity_pct', 0):.1%}")
        print(f"   æ¨ç†éˆ: {decision.get('reason_chain', 'N/A')}")

        # åˆ†æ LLM æ¨ç†
        analyze_llm_response(decision)

        # æ€§èƒ½æŒ‡æ¨™
        if "metrics" in decision:
            metrics = decision["metrics"]
            print(f"\nâš¡ æ€§èƒ½æŒ‡æ¨™:")
            print(f"   ç¸½å»¶é²: {metrics.get('total_latency_ms', 'N/A')}ms")
            print(f"   LLM å»¶é²: {metrics.get('llm_latency_ms', 'N/A')}ms")
            print(f"   Gate æª¢æŸ¥: {metrics.get('gates_latency_ms', 'N/A')}ms")

    except requests.exceptions.RequestException as e:
        print(f"âŒ API è«‹æ±‚å¤±æ•—: {e}")
    except json.JSONDecodeError as e:
        print(f"âŒ éŸ¿æ‡‰è§£æå¤±æ•—: {e}")

def test_non_borderline_case():
    """æ¸¬è©¦éé‚Šç•Œæƒ…æ³ (ä¸æ‡‰è§¸ç™¼ LLM)"""
    print("\nğŸ§ª æ¸¬è©¦éé‚Šç•Œæƒ…æ³ (ä¸æ‡‰è§¸ç™¼ LLM)")
    print("=" * 60)

    request = create_borderline_request()
    request["pgm"]["p_hit"] = 0.85  # éé‚Šç•Œå€¼

    try:
        response = requests.post(
            f"{API_BASE}/decide/enter",
            json=request,
            timeout=TIMEOUT
        )
        response.raise_for_status()
        decision = response.json()

        if "llm_reasoning" in decision:
            print("âš ï¸  éé‚Šç•Œæƒ…æ³ä¹Ÿè§¸ç™¼äº† LLM (å¯èƒ½é…ç½®æœ‰èª¤)")
        else:
            print("âœ… éé‚Šç•Œæƒ…æ³æ­£ç¢ºè·³é LLM æ¨ç†")

    except requests.exceptions.RequestException as e:
        print(f"âŒ éé‚Šç•Œæ¸¬è©¦å¤±æ•—: {e}")

if __name__ == "__main__":
    # ä¸»æ¼”ç¤º
    demonstrate_llm_reasoning()

    # å°æ¯”æ¸¬è©¦
    test_non_borderline_case()

    print("\n" + "=" * 60)
    print("âœ¨ LLM Reasoner æ¼”ç¤ºå®Œæˆ")
    print("ğŸ’¡ æç¤º: æª¢æŸ¥ logs/ ç›®éŒ„ä¸­çš„è©³ç´°æ¨ç†æ—¥èªŒ")
    print("ğŸ“š æ›´å¤šç¯„ä¾‹: examples/llm_reasoning/")